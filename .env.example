# AI Agency Platform - Environment Configuration Template
# Copy this file to .env and fill in your values
#
# For local development, you only need:
# - DATABASE_URL (use the local one below)
# - OPENAI_API_KEY (get from https://platform.openai.com/api-keys)

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Local Development (with Docker Compose)
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/ai_agency

# GCP Cloud SQL (for production)
# DATABASE_URL=postgresql+psycopg://user:pass@/dbname?host=/cloudsql/PROJECT:REGION:INSTANCE

# AWS RDS (if using AWS)
# DATABASE_URL=postgresql+psycopg://user:pass@host.rds.amazonaws.com:5432/dbname?sslmode=require

# Azure Database (if using Azure)
# DATABASE_URL=postgresql+psycopg://user@server:pass@host.postgres.database.azure.com:5432/dbname?sslmode=require

# =============================================================================
# GCP CONFIGURATION
# =============================================================================

# GCP Project ID (for Cloud Storage, Vertex AI, etc.)
GCP_PROJECT_ID=merlin-notebook-lm

# Google Cloud Storage bucket for artifacts (reports, documents, etc.)
GCS_BUCKET=merlin-ai-agency-artifacts-eu

# Vertex AI location
VERTEX_AI_LOCATION=europe-west1

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Primary LLM provider: openai | vertex | mistral (future)
LLM_PROVIDER=openai

# --- OpenAI Configuration ---
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-key-here

# OpenAI model selections (optional overrides)
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# --- Vertex AI Configuration ---
# Only needed if LLM_PROVIDER=vertex
# VERTEX_MODEL=gemini-pro
# VERTEX_EMBEDDING_MODEL=textembedding-gecko@003

# --- Mistral Configuration (Future) ---
# MISTRAL_API_KEY=your-key-here
# MISTRAL_MODEL=mistral-large-latest

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================

# Log level: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO

# Environment: development | staging | production
ENVIRONMENT=development

# Application port (default: 8080)
# PORT=8080

# =============================================================================
# SECURITY SETTINGS
# =============================================================================

# API Key for authentication (optional, for API access control)
# API_KEY=your-secret-api-key

# CORS origins (comma-separated, for frontend integration)
# CORS_ORIGINS=http://localhost:3000,https://your-frontend.com

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable/disable specific features during development
# ENABLE_RAG=true
# ENABLE_BACKGROUND_WORKER=true
# ENABLE_METRICS=true

# =============================================================================
# ADVANCED SETTINGS (Usually don't need to change)
# =============================================================================

# Database connection pool settings
# DB_POOL_SIZE=20
# DB_MAX_OVERFLOW=10

# LLM request timeouts (seconds)
# LLM_TIMEOUT=30
# LLM_MAX_RETRIES=3

# RAG settings
# RAG_CHUNK_SIZE=1000
# RAG_CHUNK_OVERLAP=200
# RAG_TOP_K=5

# Background worker settings
# WORKER_POLL_INTERVAL=5
# WORKER_MAX_CONCURRENT=5

# =============================================================================
# DEVELOPER NOTES
# =============================================================================

# For local development:
#   1. Copy this file: cp .env.example .env
#   2. Set your OPENAI_API_KEY
#   3. Use the local DATABASE_URL (already set above)
#   4. Everything else uses defaults

# For GCP deployment:
#   - Most secrets should be in Secret Manager (managed by setup_gcp.sh)
#   - Use .env.gcp for Cloud Run deployment
#   - Never commit .env to git!

# See docs/DEVELOPER_ONBOARDING.md for full setup guide
